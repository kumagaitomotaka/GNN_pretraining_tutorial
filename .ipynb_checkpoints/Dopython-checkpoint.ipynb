{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f145e448-079d-403c-b502-189b11886852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data; train:107109, valid:13388, test:13388\n",
      "homo_normalizing...mean: -0.24001650512218475, std: 0.022153044119477272, shape: 107109\n",
      "lumo_normalizing...mean: 0.011250116862356663, std: 0.04691634327173233, shape: 107109\n",
      "num_atom_features = 81\n",
      "/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python new_PL_BasicGNN_to_Hug.py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /data3/Chem/kumagai/Pretrain_models/lightning_logs\n",
      "2024-02-18 13:52:56.235406: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-18 13:52:56.290018: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-18 13:52:56.901328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | criterion | MSELoss | 0     \n",
      "1 | model     | GCN     | 27.3 K\n",
      "--------------------------------------\n",
      "27.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.3 K    Total params\n",
      "0.109     Total estimated model params size (MB)\n",
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([9176])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Traceback (most recent call last):\n",
      "  File \"new_PL_BasicGNN_to_Hug.py\", line 121, in <module>\n",
      "    main()\n",
      "  File \"new_PL_BasicGNN_to_Hug.py\", line 93, in main\n",
      "    trainer.fit(pl_model, train_loader, valid_loader)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1033, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1062, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 134, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 391, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 403, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "  File \"/data3/Chem/kumagai/Pretrain_models/models/PL_BasicGNN_models.py\", line 112, in validation_step\n",
      "    h_loss = self.criterion(pred[:,0], label_h)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/loss.py\", line 535, in forward\n",
      "    return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py\", line 3328, in mse_loss\n",
      "    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  File \"/home/kumagai/anaconda3/envs/py38/lib/python3.8/site-packages/torch/functional.py\", line 73, in broadcast_tensors\n",
      "    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]\n",
      "RuntimeError: The size of tensor a (9176) must match the size of tensor b (512) at non-singleton dimension 0\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "!python new_PL_BasicGNN_to_Hug.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
